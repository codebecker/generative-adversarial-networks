{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import fasttext\n",
    "import spacy\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "#load fasttext-> takes some while to load 7GB model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "#load any hugging face model \n",
    "model_name='distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapLabels(str_labels, id_length, dict_name):\n",
    "    # get embeddings for labels\n",
    "    dictionary = {}\n",
    "    for idx, label in enumerate(str_labels):\n",
    "        embedding = ft.get_word_vector(label)\n",
    "        dictionary[idx] = embedding\n",
    "    with open('./' + dict_name + '_embeddings.pickle', 'wb') as handle:\n",
    "        pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52103b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapTransformerLabels(str_labels, id_length, dict_name):\n",
    "    # get embeddings for labels\n",
    "    dictionary = {}\n",
    "    for idx, label in enumerate(str_labels):\n",
    "        input_ids = torch.tensor(tokenizer.encode(label)).unsqueeze(0) # Batch size 1\n",
    "        embedding = model(input_ids)[0][0][0].detach().numpy() \n",
    "        dictionary[idx] = embedding\n",
    "    with open('./transformers/' + dict_name + '_embeddings.pickle', 'wb') as handle:\n",
    "        pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fleet-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_mnist = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'zero']\n",
    "labels_cifar = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "labels_fmnist = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag' , 'ankle boot']\n",
    "\n",
    "str_labels = labels_cifar\n",
    "id_length = len(str_labels)\n",
    "mapTransformerLabels(str_labels, id_length, \"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671976b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19b193b21597b2531432d1ee43d2250207971705cde282ed77abb510e1e1e7ed"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}